{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in Recipe Data from Epicurious \n",
    "\n",
    "Load in 13,000 recipes from epicurious. We want to see that given the nutritional value of a recipe — particularly calories, protein, fat and sodium — could we predict what the rating would be for the particular recipe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('epicurious-recipes.csv', encoding='utf-8')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's look at the data to see some comparisons might exist\n",
    "\n",
    "We'll do a pairplot to see if there are any correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df, vars=['rating','calories','protein','fat','sodium'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup X and y variables\n",
    "\n",
    "X is going to be the values we input into the system. It's traditionally capitalized because it's an input as in f(x) = y. In RandomForest, we setup the following variables\n",
    "\n",
    "X - All of the numerical variables that we will use to predict new value\n",
    "y - The label we're trying to match, and find a new species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['calories', 'protein', 'fat', 'sodium']]\n",
    "y = df['rating'].apply(lambda x: int(x * 1000)) #multiply ratings by 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split our data into four parts\n",
    "\n",
    "This will create four variables:\n",
    "\n",
    "* `X_train` - This will have 80 percent rows in our X columns. They're randomly chosen.\n",
    "* `X_text`  - This will have the remaining 20 percent of the X columns to test against.\n",
    "* `y_train` - This will have 80 percent of our y or (rating) column, randomly selected.\n",
    "* `y_test`  - This will have the remaining 20 percent of the ratings to test against."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "print('Number of observations in the training data:', len(X_train))\n",
    "print('Number of observations in the test data:',len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup our classifier\n",
    "\n",
    "* `n_jobs` specifies how much processor we're devoting to this task (concurrent processes).\n",
    "* `n_estimators` is how many trees in the forest to use (100 is default in recent versions).\n",
    "* `random_state` is the random seed. It's optional, but specifying it will give you the same results every time this is run. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestRegressor(n_jobs=2, n_estimators=100, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup the Actual Model\n",
    "\n",
    "This is the \"machine learning\" part, where we fit our model based on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict using the test data\n",
    "\n",
    "Now that we have our classifier, we'll predict results with our 20 percent test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create table of predictions\n",
    "\n",
    "Now that we have our classifier, let's see how accurate it is by making a table and graphing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert back to rating values by dividing by 1000\n",
    "act_rating = np.vectorize(lambda x: float(x/1000))(y_test)\n",
    "pre_rating = np.vectorize(lambda x: float(x/1000))(y_pred)\n",
    "\n",
    "df2 = pd.DataFrame({'Actual': act_rating, 'Predicted': pre_rating})\n",
    "df2['Difference'] = df2['Predicted'] - df2['Actual']\n",
    "df2.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(df2['Difference'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Standard deviation:\", df2['Difference'].std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's see how accurate we were\n",
    "\n",
    "0.5 means 50%, which means we got _exact_ results about half the time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Accuracy:\", clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's see which of the variables our classifier preferred\n",
    "\n",
    "This will tell us how much our classifier weighed each variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see importance of each variable\n",
    "feature_imp = pd.DataFrame({'variable':list(X_train.columns), 'importance': clf.feature_importances_}).sort_values(by='importance',ascending=False)\n",
    "feature_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(y='variable', x='importance', kind='bar', orient='h', data=feature_imp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict a one-off\n",
    "\n",
    "Let's provide values for calories, protein, fat and sodium and see what rating it would predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calories, protein, fat,sodium\n",
    "oneoff = clf.predict([[100, 10, 7, 550]])\n",
    "\n",
    "print(\"Predicted rating: \", float(oneoff/1000))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
